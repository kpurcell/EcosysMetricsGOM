---
title: "Size-Based Indicator Analysis"
author: "Kevin M. Purcell"
date: "Tuesday, November 18, 2014"
output: html_document
---

## Objectives
Identify and calculate size-based indicator (SBI) time series for the Gulf of Mexico based on the length-frequency data collected by [SEAMAP]() for our focal species.  Indicatory identification is derived from two primary sources [Shin et al. 2005](http://icesjms.oxfordjournals.org/content/62/3/384) and [Rochet and Trinkle 2003](http://www.nrcresearchpress.com/doi/abs/10.1139/f02-164).  Initially a global time series will be developed for community-wide metrics of mean length:

$ \bar{L}=\frac{\sum\limits_{N}L}{N} $  

Additionally, a community estimate of mean weight:

$ \bar{W}=\frac{B}{N} $  

will also be generated and trends over the survey period will be assessed.




## Methods

1. Bring in size frequency and supporting SEAMAP data
```{r dataImport, echo=FALSE}
#library(magrittr)
library(dplyr)
library(stargazer)
# Import Size frequency table from SEAMAP_2013 DB
# sfDat <- read.csv("C:/Users/Kevin.Purcell/Documents/seamap_2013/GLFREC.csv", 
#                    header = TRUE, sep = ",")

sfDat <- read.csv("C:/Users/Kevin.Purcell/Documents/seamap_2013/GLFREC2.csv", 
                    header = TRUE, sep = ",")
# GLFREC2.csv was the second attempt to extract the data from the Access DB.
# The initial export (ie GLFREC.csv) only exported around 1M values as opposed

# create a new variable to be a factor for measurement type
sfDat$meas_typ <- sfDat$MEASCD_GLF

# Recode the new variable to letter designations for filtering
sfDat$meas_typ[sfDat$meas_typ==1] <- "FL"
sfDat$meas_typ[sfDat$meas_typ==2] <- "SL"
sfDat$meas_typ[sfDat$meas_typ==3] <- "TL"
sfDat$meas_typ[sfDat$meas_typ==4] <- "TL"
sfDat$meas_typ[sfDat$meas_typ==5] <- "WD"
sfDat$meas_typ[sfDat$meas_typ==6] <- "TL"
sfDat$meas_typ[sfDat$meas_typ==8] <- "TL"
sfDat$meas_typ[sfDat$meas_typ==10] <- "WD"
sfDat$meas_typ[sfDat$meas_typ==11] <- "TL"
sfDat$meas_typ[sfDat$meas_typ==12] <- "TL"
sfDat$meas_typ[sfDat$meas_typ==13] <- "ML"
sfDat$meas_typ[sfDat$meas_typ==14] <- "WD"
sfDat$meas_typ[sfDat$meas_typ==15] <- "TRD"
sfDat$meas_typ[sfDat$meas_typ==16] <- "WD"
sfDat$meas_typ[sfDat$meas_typ==17] <- "TL"
sfDat$meas_typ[sfDat$meas_typ==18] <- "TL"
sfDat$meas_typ[sfDat$meas_typ==19] <- "UNKNOWN"
sfDat$meas_typ[sfDat$meas_typ==20] <- "OTHER"
sfDat$meas_typ[sfDat$meas_typ==22] <- "WD"
sfDat$meas_typ[sfDat$meas_typ==23] <- "SA"


# Import station table from SEAMAP_2013 DB
stDat <- read.csv("C:/Users/Kevin.Purcell/Documents/seamap_2013/STAREC.csv", 
                    header = TRUE, sep = ",")

# Create a yr and month variable
stDat$date<-stDat$MO_DAY_YR
stDat$date<-as.Date(stDat$date, "%m/%d/%Y")
stDat$month<-format(stDat$date, format="%m")
stDat$YR<-format(stDat$date, format="%Y")
stDat$YR<-as.numeric(stDat$YR)
stDat$month<-as.numeric(stDat$month)

#Import the Taxonomy data from SEAMAP_2013 DB
taxDat <- read.csv("C:/Users/Kevin.Purcell/Documents/seamap_2013/NEWBIOCODESBIG.csv", header = TRUE, sep = ",")

# Import BGSREC table
bgsDat <- read.csv("C:/Users/Kevin.Purcell/Documents/seamap_2013/BGSREC.csv", header = TRUE, sep = ",")

# Filter only needed columns
# names(bgsDat)
# head(bgsDat)

# bgsDat1 <- select(bgsDat, STATIONID, CNTEXP, BIO_BGS, IS_SAMPLE)
# head(sbiDat3)

# lenCount <- sbiDat3 %>%
#   filter(STATIONID==4) %>%
#   group_by(BIO_GLF, common_name) %>%
#   summarize(spcCnt=n(), meanL)

```


```{r sfTable, echo=FALSE, results='asis', warning=FALSE, error=FALSE, message=FALSE}

shortnames=names(sfDat)
#create variable descriptions
description <- c("unique integer (int) entry id",
                 "unique int for ea. entry in CRUSIES table",
                 "Unique int for ea. entry in BGSREC table",
                 "unique int for ea. entry in STAREC table",
                 "unique int for ea. entry in VESSELS table",
                 "four character (ch.) string format YYXX",
                 "five ch. string for Pascagoula Station No.",
                 "9 digit field for Genus species biocode",
                 "no current used",
                 "7 ch. field for Genus",
                 "6 ch. field for species",
                 "4 digit XXX.X field for weight (kg)",
                 "2 ch. field containing measurement code",
                 "4 ch. field (numeric) of length (mm)",
                 "1 ch. field representing sex (M, F, U) can be blank",
                 "1 ch. field representing maturity code")

metadataBound <- cbind(shortnames, description)
colnames(metadataBound) <- c("Parameter", "Description")
stargazer(metadataBound, type = "text", summary = FALSE)
```


2. Attached locations or sampling sites to size based data
```{r}
# Do this later to avoid choking on data

sbiDat1 <- dplyr::inner_join(sfDat, stDat, by = "STATIONID", copy = FALSE)

```


3. Limit the dataset based on the 65 species used in the study
Follow up on other sections to verify the number of species.
```{r}
#Import list of study species
studySpecies<-read.csv("C:/Users/kevin.purcell/Documents/comm_analysis/seamap_keepers_comm_analysis.csv")
#studySpecies$keep <- NULL
colnames(studySpecies)[1] <- "BIO_GLF"

#return all rows from x where there are matching values in y, keeping just columns from x. 
# Essentially filter data to only Species in our "LIST"
sbiDat2 <- dplyr::inner_join(sbiDat1, studySpecies, by = NULL, copy = FALSE)
names(sbiDat2)
# check
length(unique(sbiDat2$BIO_GLF))


```

4. Attach taxonomic info to the database
```{r}
#change the column name in taxDat to BIO_GLF
colnames(taxDat)[3] <- "BIO_GLF"

#join taxonomy data to database
sbiDat3 <- dplyr::inner_join(sbiDat2, taxDat, by = NULL, copy = FALSE)

# species table
specTable <- dplyr::inner_join(studySpecies, taxDat, by = NULL, copy = FALSE) %>%
  select(BIO_GLF, TAXONOMIC, common_name)
colnames(specTable)[1] <- "Code"
colnames(specTable)[2] <- "Genus species"
colnames(specTable)[3] <- "Common name"

stargazer(specTable, type = "text", summary = FALSE, digit.separator = "")

```

5. Attach station count data to allow for weighted averaging
```{r}
#sbiDat4 <- dplyr::inner_join(sbiDat3, bgsDat1, by = NULL, copy = FALSE)


```


6. Reduce the GLFREC DB first
```{r}
head(sfDat)
# First calculate the number measured and sum of the lengths
# for each species at each station
glfRed <- sfDat %>%
  inner_join(sfDat, studySpecies, by = NULL, copy = FALSE)
  filter(meas_typ=="TL") %>%
  group_by(STATIONID, BIO_GLF) %>%
  summarize(msrCnt=n(), 
            sumL=sum(LEN_GLF))

# Tests to verify counts
head(glfRed)
glfRedTest <- sfDat %>%
  filter(BIO_GLF==108021802, STATIONID==4)
  
```

7. Summarize and calculate the cntexp
```{r}
names(bgsDat)
bgsRed <- bgsDat %>%
  group_by(STATIONID, BIO_BGS) %>%
  summarize(totCatch=sum(CNTEXP))
```



6. Calculate the global community Mean length metric by year for TL
```{r}
#length by year
#sum by yeara
#generate mean length by year
df1 <- sbiDat3[c(67,17,14)] 
df2 <- subset(df1, df1$meas_typ=="TL")
mean_len <- aggregate(LEN_GLF ~ YR, data=df2, mean)
colnames(mean_len)[2] <- "meanLen"
sd_len <- aggregate(LEN_GLF ~ YR, data=df2, sd)
colnames(sd_len)[2] <- "sd"
mean_len <- merge(mean_len, sd_len, by="YR")
ggplot2::qplot(YR, meanLen, data=mean_len) +
  geom_point()
, geom=c("point", "smooth"))

ggplot2::ggplot(mean_len, aes(x=YR, y=meanLen)) + 
  geom_point() +
  geom_line() +
  geom_errorbar(aes(ymin=meanLen-sd, ymax=meanLen+sd), width=.1)
   
# Mean weight calculation
#df3 <- sbiDat3[c(67,12)]
#mean_wt <- aggregate(INDVL_WT ~ YR, data=df3, mean)
#%%%%%%%%%%%%%%%% NOT POSSIBLE DUE TO NAs %%%%%%%%%%%%%%%%%%%%%%#

```



3. Derive size based indicators from initial size sampling data
```{r}
meanLen <- sum()


```




4. Evaluate temporal patterns of indicators


